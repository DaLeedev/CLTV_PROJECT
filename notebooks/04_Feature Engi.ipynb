{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609b5410",
   "metadata": {},
   "source": [
    "# Transformacion de los Datos para Modelado CLTV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefdcec4",
   "metadata": {},
   "source": [
    "Esta estapa es crucial para preparar el dataset para el modelado del CLTV con Redes Neuronales. Esta fase se realiza ya que no se pueden usar los datos tal cual como estan antes de esta etapa, se requiere transformar el registro de transacciones que esta en formato (filas por compras) a un formato de registros por cliente (una fila por cliente) estructurado en ventanas de tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ba7e9181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "df = pd.read_parquet('../data/processed/online_retail_II_cleaned.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033ead05",
   "metadata": {},
   "source": [
    "## Creacion de Nueva Variable en el Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece17c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadísticas de totalamount:\n",
      "count    400916.000000\n",
      "mean         21.945330\n",
      "std          77.734238\n",
      "min           0.001000\n",
      "25%           5.000000\n",
      "50%          12.500000\n",
      "75%          19.500000\n",
      "max       15818.400391\n",
      "Name: totalamount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df['totalamount'] = df['quantity'] * df['price'] #Se crea la nueva variable totalamount\n",
    "\n",
    "# Verificación rápida\n",
    "print(\"Estadísticas de totalamount:\")\n",
    "print(df['totalamount'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d5e574",
   "metadata": {},
   "source": [
    "Se crea la variable `totalamount` que representa el monto total gastado por cada transaccion, calculado como la multiplicacion de las series `quantity` y `price`.\n",
    "\n",
    "La creacion de esta nueva variable es esencial para el analisis del CLTV, ya que a nivel cliente, el CLTV se calcula en base al monto total gastado por cada cliente en un periodo de tiempo determinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "0d118205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400916 entries, 0 to 400915\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count   Dtype         \n",
      "---  ------       --------------   -----         \n",
      " 0   invoice      400916 non-null  string        \n",
      " 1   stockcode    400916 non-null  string        \n",
      " 2   description  400916 non-null  string        \n",
      " 3   quantity     400916 non-null  int16         \n",
      " 4   invoicedate  400916 non-null  datetime64[ns]\n",
      " 5   price        400916 non-null  float32       \n",
      " 6   customer_id  400916 non-null  Int32         \n",
      " 7   country      400916 non-null  string        \n",
      " 8   totalamount  400916 non-null  float32       \n",
      "dtypes: Int32(1), datetime64[ns](1), float32(2), int16(1), string(4)\n",
      "memory usage: 21.0 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190057d3",
   "metadata": {},
   "source": [
    "## Horizonte de Tiempo y Ventanas Móviles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16bb836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando Ventana 1: Obs[2009-12-01 a 2010-03-01) -> Target[2010-03-01 a 2010-09-01]\n",
      "Procesando Ventana 2: Obs[2010-01-01 a 2010-04-01) -> Target[2010-04-01 a 2010-10-01]\n",
      "Procesando Ventana 3: Obs[2010-02-01 a 2010-05-01) -> Target[2010-05-01 a 2010-11-01]\n",
      "Procesando Ventana 4: Obs[2010-03-01 a 2010-06-01) -> Target[2010-06-01 a 2010-12-01]\n",
      "\n",
      "Dataset Final Generado: 7509 registros totales.\n",
      "Ejemplos promedio por cliente: 2.78\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>recency</th>\n",
       "      <th>frequency</th>\n",
       "      <th>monetary</th>\n",
       "      <th>product_variety</th>\n",
       "      <th>month_start</th>\n",
       "      <th>target_cltv_6m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12346</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>203.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>169.360001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12358</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>1429.829956</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>268.100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12359</td>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>838.890015</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>1173.140015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12360</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>662.039978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12361</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>109.199997</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>98.150002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  recency  frequency     monetary  product_variety  month_start  \\\n",
       "0        12346       37          9   203.500000                2           12   \n",
       "1        12358       82          1  1429.829956               17           12   \n",
       "2        12359       74          2   838.890015               34           12   \n",
       "3        12360        6          1   118.000000               10           12   \n",
       "4        12361       33          1   109.199997                7           12   \n",
       "\n",
       "   target_cltv_6m  \n",
       "0      169.360001  \n",
       "1      268.100006  \n",
       "2     1173.140015  \n",
       "3      662.039978  \n",
       "4       98.150002  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ventanas = [] # se define lista para almacenar las ventanas generadas en el bucle\n",
    "\n",
    "\n",
    "# Solo podemos empezar en meses donde tengamos 9 meses por delante (3 obs + 6 target)\n",
    "# Bucle para crear las fechas de inicio de cada ventana\n",
    "fechas_inicio = [pd.Timestamp('2009-12-01') + relativedelta(months=i) for i in range(4)]\n",
    "fecha_fin = df['invoicedate'].max().normalize()\n",
    "\n",
    "for i, start_date in enumerate(fechas_inicio):\n",
    "    # Definir fechas clave para esta ventana\n",
    "    division_fechas = start_date + relativedelta(months=3)  # Fin de X, Inicio de y\n",
    "    end_window_date = division_fechas + relativedelta(months=6) # Fin de y\n",
    "\n",
    "    # Validar que no nos pasemos del final de los datos reales\n",
    "    if end_window_date > fecha_fin + pd.Timedelta(days=5): # Margen de error pequeño\n",
    "        print(f\"Ventana {i+1} descartada: termina en {end_window_date}, data termina en {fecha_fin}\")\n",
    "        break\n",
    "\n",
    "    print(f\"Procesando Ventana {i+1}: Obs[{start_date.date()} a {division_fechas.date()}) -> Target[{division_fechas.date()} a {end_window_date.date()}]\")\n",
    "\n",
    "    # 1. Filtrar Datos para X (Observación - 3 meses)\n",
    "    df_X = df[(df['invoicedate'] >= start_date) & (df['invoicedate'] < division_fechas)]\n",
    "\n",
    "    # 2. Filtrar Datos para y (Target - 6 meses)\n",
    "    df_y = df[(df['invoicedate'] >= division_fechas) & (df['invoicedate'] <= end_window_date)]\n",
    "\n",
    "    # 3. Construir Features (X)\n",
    "    X_window = df_X.groupby('customer_id').agg({\n",
    "        'invoicedate': lambda x: (division_fechas - x.max()).days, # Recency relativa al corte\n",
    "        'invoice': 'nunique',\n",
    "        'totalamount': 'sum',\n",
    "        'stockcode': 'nunique'\n",
    "    }).reset_index()\n",
    "    X_window.columns = ['customer_id', 'recency', 'frequency', 'monetary', 'product_variety']\n",
    "\n",
    "    # Feature Contextual: Añadimos el mes de inicio para que el modelo sepa la estacionalidad\n",
    "    X_window['month_start'] = start_date.month\n",
    "\n",
    "    # 4. Construir Target (y)\n",
    "    y_window = df_y.groupby('customer_id')['totalamount'].sum().reset_index()\n",
    "    y_window.columns = ['customer_id', 'target_cltv_6m']\n",
    "\n",
    "    # 5. Unir y Etiquetar\n",
    "    window_data = pd.merge(X_window, y_window, on='customer_id', how='left')\n",
    "    window_data['target_cltv_6m'] = window_data['target_cltv_6m'].fillna(0)\n",
    "    # Agregar a la lista ventanas antes creada\n",
    "    ventanas.append(window_data)\n",
    "\n",
    "# Concatenar todas las ventanas en un solo gran dataset\n",
    "df_model_rolling = pd.concat(ventanas, ignore_index=True)\n",
    "\n",
    "print(f\"\\nDataset Final Generado: {df_model_rolling.shape[0]} registros totales.\")\n",
    "print(f\"Ejemplos promedio por cliente: {df_model_rolling.shape[0] / df_model_rolling['customer_id'].nunique():.2f}\")\n",
    "df_model_rolling.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be13a76",
   "metadata": {},
   "source": [
    "Se utilizan ventanas móviles para capturar la evolución del comportamiento del cliente a lo largo del tiempo. Cada ventana consta de un periodo de observación (X) y un periodo objetivo (y).\n",
    "- Periodo de Observación (X): 3 meses\n",
    "- Periodo Objetivo (y): 6 meses\n",
    "Se crean múltiples ventanas móviles para cubrir diferentes periodos de tiempo en el dataset, permitiendo capturar cambios en el comportamiento del cliente.\n",
    "#### Generacion de Ventanas Móviles\n",
    "Se generan ventanas móviles utilizando un bucle que itera sobre las fechas de inicio definidas. Para cada ventana, se definen las fechas clave para el periodo de observación y el periodo objetivo, y se extraen las características (X) y la variable objetivo (y) correspondientes a cada ventana. Finalmente, se combinan las características y la variable objetivo en un solo dataset para cada ventana, y se almacenan en una lista para su posterior concatenación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3f6a27",
   "metadata": {},
   "source": [
    "## Pipeline de Transformacion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "5729d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4b7a94",
   "metadata": {},
   "source": [
    "### 1. Transformacion logarítmica (corregir el sesgo de Pareto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078df8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos Logaritmo (log(x + 1))\n",
    "# Esto comprime los valores gigantes (outliers) y ayuda a la red neuronal a converger.\n",
    "cols_to_log = ['recency', 'frequency', 'monetary', 'product_variety', 'target_cltv_6m']\n",
    "\n",
    "for col in cols_to_log:\n",
    "    # No s filtran negativos porque ya no existen en nuestro dataset, anteriormente fue limpiado y validado\n",
    "    df_model_rolling[col] = np.log1p(df_model_rolling[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96132264",
   "metadata": {},
   "source": [
    "La transformacion logaritmica se aplica a las variables `recency`, `frequency`, `monetary`, `product_variety` y `target_cltv_6m` utilizando la funcion `log1p` de numpy. Esta transformacion comprime los valores extremos (outliers) y ayuda a la red neuronal a estabilizarse y  obtener mejor eficiencia durante el entrenamiento, reduciendo el sesgo que introducen los outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac8dbdf",
   "metadata": {},
   "source": [
    "### 2. Codificación de Estacionalidad (One-Hot Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fc5070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos el mes de inicio de la ventana en columnas binarias (categoricas) usando One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df_model_rolling, columns=['month_start'], prefix='start_month', dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0b7bc6",
   "metadata": {},
   "source": [
    "Se convierte la variable categórica `month_start`, que indica el mes de inicio de cada ventana móvil, en variables binarias (one-hot encoding). Esto permite que el modelo capture patrones estacionales en el comportamiento del cliente relacionados con el mes de inicio de la ventana."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90054203",
   "metadata": {},
   "source": [
    "### 3. División de Datos en Conjuntos de Entrenamiento y Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde1e132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset de Entrenamiento: 2162 clientes | 6042 ventanas\n",
      "Dataset de Prueba:        541 clientes | 1467 ventanas\n"
     ]
    }
   ],
   "source": [
    "# Garantizamos que un cliente y todas sus ventanas temporales caigan en el mismo grupo\n",
    "unique_customers = df_encoded['customer_id'].unique()\n",
    "n_customers = len(unique_customers)\n",
    "\n",
    "# Semilla para reproducibilidad\n",
    "np.random.seed(42)\n",
    "shuffled_ids = np.random.permutation(unique_customers)\n",
    "\n",
    "# 80% Entrenamiento / 20% Prueba\n",
    "split_idx = int(n_customers * 0.8)\n",
    "train_ids = shuffled_ids[:split_idx]\n",
    "test_ids = shuffled_ids[split_idx:]\n",
    "\n",
    "# Filtramos el dataFrame\n",
    "train_df = df_encoded[df_encoded['customer_id'].isin(train_ids)]\n",
    "test_df = df_encoded[df_encoded['customer_id'].isin(test_ids)]\n",
    "\n",
    "print(f\"Dataset de Entrenamiento: {len(train_ids)} clientes | {len(train_df)} ventanas\")\n",
    "print(f\"Dataset de Prueba:        {len(test_ids)} clientes | {len(test_df)} ventanas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7fa890",
   "metadata": {},
   "source": [
    "La division de los datos se realiza a nivel de cliente para evitar la fuga de datos entre el conjunto de entrenamiento y prueba. Se asegura que todas las ventanas temporales de un mismo cliente caigan en el mismo conjunto, ya sea de entrenamiento o prueba. Esto es crucial para evaluar correctamente el rendimiento del modelo en datos no vistos durante el entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe95b7",
   "metadata": {},
   "source": [
    "### 4. Estandariazación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e010abeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensiones listas para la Red Neuronal:\n",
      "Inputs (X): (6042, 8)\n"
     ]
    }
   ],
   "source": [
    "# Separar features y target\n",
    "features_col = [c for c in df_encoded.columns if c not in ['customer_id', 'target_cltv_6m']]\n",
    "target_col = 'target_cltv_6m'\n",
    "\n",
    "X_train = train_df[features_col].values\n",
    "y_train = train_df[target_col].values\n",
    "\n",
    "X_test = test_df[features_col].values\n",
    "y_test = test_df[target_col].values\n",
    "\n",
    "# El scaler aprende solo del set de entrenamiento para evitar \"Fuga de Datos\"\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) # Solo transforma el test, no aprende de él\n",
    "\n",
    "print(f\"\\nDimensiones listas para la Red Neuronal:\")\n",
    "print(f\"Inputs (X): {X_train_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3175f87",
   "metadata": {},
   "source": [
    "Se aplica la estandarizacion de los datos utilizando el StandardScaler de sklearn. Este proceso transforma las características para que tengan una media de 0 y una desviación estándar de 1, lo que ayuda a mejorar la convergencia del modelo durante el entrenamiento. El scaler se ajusta únicamente con los datos de entrenamiento para evitar la fuga de datos (data leakage) y luego se aplica tanto al conjunto de entrenamiento como al de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004659a6",
   "metadata": {},
   "source": [
    "### 5. Preparación y guardado de datos para entrenamiento de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32da43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando archivos en 'data/processed/'...\n",
      "¡Proceso de Feature Engineering finalizado y guardado!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "os.makedirs('../data/processed/', exist_ok=True) #crear carpeta si no existe\n",
    "\n",
    "print(\"Guardando archivos en 'data/processed/'...\")\n",
    "\n",
    "# Arrays Matemáticos (Para la Red Neuronal)\n",
    "joblib.dump(X_train_scaled, '../data/processed/X_train_scaled.pkl', compress=3)\n",
    "joblib.dump(X_test_scaled, '../data/processed/X_test_scaled.pkl', compress=3)\n",
    "joblib.dump(y_train, '../data/processed/y_train.pkl', compress=3)\n",
    "joblib.dump(y_test, '../data/processed/y_test.pkl', compress=3)\n",
    "\n",
    "# El Scaler (necesario para re-transformar datos en el futuro)\n",
    "joblib.dump(scaler, '../data/processed/scaler.pkl')\n",
    "\n",
    "# Datos de Contexto (Para saber que cliente es cada predicción después)\n",
    "# Guardamos el DF original (con IDs) y las listas de IDs de train/test\n",
    "df_model_rolling.to_parquet('../data/processed/df_model_rolling.parquet')\n",
    "joblib.dump(train_ids, '../data/processed/train_ids.pkl')\n",
    "joblib.dump(test_ids, '../data/processed/test_ids.pkl')\n",
    "\n",
    "# Guardar los nombres de las columnas después del One-Hot Encoding\n",
    "joblib.dump(features_col, '../data/processed/model_columns.pkl') #vital para alinear las columnas en producción\n",
    "\n",
    "print(\"Feature Engineering finalizado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cltv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
